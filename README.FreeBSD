
Last updated: 2017-07-14

The FreeBSD build will build most of the tools in Ceph.
Note that the (kernel) RBD dependant items will not work

I started looking into Ceph, because the HAST solution with CARP and 
ggate did not really do what I was looking for. But I'm aiming for 
running a Ceph storage cluster on storage nodes that are running ZFS.
In the end the cluster would be running bhyve on RBD disk that are stored in 
Ceph.

The FreeBSD build will build most of the tools in Ceph.

Progress from last report:
==========================
     
Most important changes:
 - Ceph has released the release candidate of v12.1.0 (aka Luminous),
   the port is sitting in my tree waiting for Luminous to be actually 
   released.
 - ceph-fuse works, and allows mounting of cephfs filesystems. 
   Speed is not impressive, but is does work.
 - rbd-ggate available to create a device on a Ceph rbd pool.
   rbd-ggate was submitted by Mykola Golub
   That works rather simple:
     "build a cluster" 
     dd if=/dev/zero of=/tmp/image.1G bs=1M count=1k
     rdb --pool rbd import /tmp/image.1G newdevice
     rbd-gate map rbd/newdevice
     newfs /dev/ggate
   And there is a 1G disk stored on a ceph-cluster.

Other improvements:
 - bugs in the init-ceph code (needed for rc.d) are being fixed
 - RBD and rados work,
 - compatability code was written so FreeBSD and Linuxs daemons can 
   operate together.
 - More of the awkward dependancies on Linux-isms are deleted only 
   But /bin/bash is there to stay.

Expected real soon:
  The next official release of Ceph is called Luminous (v12.1.0).
  As soon as that is available, a port will be made available.

Parts not (yet) included:
=========================
      
 - KRBD
   Use rbd-ggate
 - BlueStore.
   FreeBSD and Linux have different AIO API, and that needs to be made 
   compatible. Next to that is there discussion in FreeBSD about 
   aio_cancel not working for all devicetypes

   
Build Prerequisites
===================

   Compiling and building Ceph is tested on 12-CURRENT/clang 4.0.0, 
   but  11.0-RELEASE/clang 3.8.0 will also build.  3.7 is no longer tested, 
   but that version was working when building on 11-CURRENT. 
   Clang 3.4 (on 10.2-STABLE) does not have all required capabilites to 
   compile everything.

   The following will get things running for FreeBSD:
   (It requires root priviledges.)

 - Install bash and link it in /bin
   sudo pkg install bash
   sudo ln -s /usr/local/bin/bash /bin/bash

Getting the FreeBSD version for Ceph:
=====================================

 - cd "place to work on this"
   git clone https://github.com/wjwithagen/ceph.git
   cd ceph
   git checkout wip.FreeBSD.201708

Building Ceph
=============
 - Go and start building
   ./do_freebsd.sh
   
Tasks to do:
===========
 - Run integration tests to see if the FreeBSD daemons will work with a 
   Linux Ceph platform.

 - Investigate the keystore, which could be kernel embedded on Linux an 
   currently prevents building Cephfs and some other parts.

 - Scheduler information is not used atm, because the schedulers work 
   rather different. But at a certain point in time, this would need some 
   attention:
   in: ./src/common/Thread.cc

 - Improve the FreeBSD /etc/rc.d initscripts in the Ceph stack. Both 
   for testing, but mainly for running Ceph on production machines.
   Work on ceph-disk and ceph-deploy to make it more FreeBSD and ZFS 
   compatible. 

 - Build test-cluster and start running some of the teuthology integration 
   tests on these.
   Teuthology wants to build its own libvirt and that does not quite work
   with all the packages FreeBSD already has in place. Lots of minute 
   details to figure out

 - Design a virtual disk implementation that can be used with bhyve and 
   attached to an RBD image. 
